{"cells":[{"cell_type":"markdown","source":["# Reading Data Lab\n* The goal of this lab is to put into practice some of what you have learned about reading data with Apache Spark.\n* The instructions are provided below along with empty cells for you to do your work.\n* At the bottom of this notebook are additional cells that will help verify that your work is accurate."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0210b82-45a8-4a2a-a6b9-95e3dea3f0aa"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n0. Start with the file **dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv**, some random file you haven't seen yet.\n0. Read in the data and assign it to a `DataFrame` named **testDF**.\n0. Run the last cell to verify that the data was loaded correctly and to print its schema.\n0. The one untestable requirement is that you should be able to create the `DataFrame` and print its schema **without** executing a single job.\n\n**Note:** For the test to pass, the following columns should have the specified data types:\n * **prev_id**: integer\n * **curr_id**: integer\n * **n**: integer\n * **prev_title**: string\n * **curr_title**: string\n * **type**: string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c034eb4-543c-43fe-9647-c3835bcd8449"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa0effa7-68d2-4298-a5fb-b5e9e22c6555"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e6bf135-2dea-4428-b8fc-aac6d2a32ed3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b73c36b-18c1-4242-ad85-e5e807ba4a9b"}}},{"cell_type":"code","source":["# TODO\n\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\ntestDF = <<FILL_IN>>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb318688-b1b3-43a7-b6c2-1dd2457a9e05"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly.\n\n**Remember:** This should execute without triggering a single job."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"debe201f-14f6-4870-94af-f4f41613e9c2"}}},{"cell_type":"code","source":["testDF.printSchema()\n\ncolumns = testDF.dtypes\nassert len(columns) == 6, \"Expected 6 columns but found \" + str(len(columns))\n\nassert columns[0][0] == \"prev_id\",    \"Expected column 0 to be \\\"prev_id\\\" but found \\\"\" + columns[0][0] + \"\\\".\"\nassert columns[0][1] == \"int\",        \"Expected column 0 to be of type \\\"int\\\" but found \\\"\" + columns[0][1] + \"\\\".\"\n\nassert columns[1][0] == \"curr_id\",    \"Expected column 1 to be \\\"curr_id\\\" but found \\\"\" + columns[1][0] + \"\\\".\"\nassert columns[1][1] == \"int\",        \"Expected column 1 to be of type \\\"int\\\" but found \\\"\" + columns[1][1] + \"\\\".\"\n\nassert columns[2][0] == \"n\",          \"Expected column 2 to be \\\"n\\\" but found \\\"\" + columns[2][0] + \"\\\".\"\nassert columns[2][1] == \"int\",        \"Expected column 2 to be of type \\\"int\\\" but found \\\"\" + columns[2][1] + \"\\\".\"\n\nassert columns[3][0] == \"prev_title\", \"Expected column 3 to be \\\"prev_title\\\" but found \\\"\" + columns[3][0] + \"\\\".\"\nassert columns[3][1] == \"string\",     \"Expected column 3 to be of type \\\"string\\\" but found \\\"\" + columns[3][1] + \"\\\".\"\n\nassert columns[4][0] == \"curr_title\", \"Expected column 4 to be \\\"curr_title\\\" but found \\\"\" + columns[4][0] + \"\\\".\"\nassert columns[4][1] == \"string\",     \"Expected column 4 to be of type \\\"string\\\" but found \\\"\" + columns[4][1] + \"\\\".\"\n\nassert columns[5][0] == \"type\",       \"Expected column 5 to be \\\"type\\\" but found \\\"\" + columns[5][0] + \"\\\".\"\nassert columns[5][1] == \"string\",     \"Expected column 5 to be of type \\\"string\\\" but found \\\"\" + columns[5][1] + \"\\\".\"\n\nprint(\"Congratulations, all tests passed... that is if no jobs were triggered :-)\\n\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5975eac-9a4e-4ca3-a209-8c54e055ae82"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"6.Reading Data - Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3013059022292932}},"nbformat":4,"nbformat_minor":0}
