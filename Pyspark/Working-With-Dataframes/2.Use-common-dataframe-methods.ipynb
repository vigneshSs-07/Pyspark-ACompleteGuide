{"cells":[{"cell_type":"markdown","source":["# Use common DataFrame methods\n\nIn the previous notebook, you ended off by executing a count of records in a DataFrame. We will now build upon that concept by introducing common DataFrame methods."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bfaad047-e724-45f4-bb49-e68e9406a6c0"}}},{"cell_type":"markdown","source":["**Technical Accomplishments:**\n* Develop familiarity with the `DataFrame` APIs\n* Use common DataFrame methods for performance\n* Explore the Spark API documentation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed6059ef-f2dc-489c-bb5e-99fbbe639df8"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35dc62e4-3218-41ed-a85e-d961141d9a7f"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc69bf37-44dc-46d7-8437-c212afbbc2e1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Initialized classroom variables & functions...","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Initialized classroom variables & functions..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Datasets are already mounted to <b>/mnt/training</b> from <b>wasbs://training@dbtraineastus.blob.core.windows.net/</b>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Datasets are already mounted to <b>/mnt/training</b> from <b>wasbs://training@dbtraineastus.blob.core.windows.net/</b>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Created user-specific database","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Created user-specific database"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using the database <b style=\"color:green\">vsekar_cloudseclab2_com_db</b>.","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Using the database <b style=\"color:green\">vsekar_cloudseclab2_com_db</b>."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All done!","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["All done!"]}}],"execution_count":0},{"cell_type":"markdown","source":["Prepare the data source."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"539cbf7b-54dd-4dcb-b350-ab579ae73b81"}}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\n\nspark.conf.set(sasEntity, sasToken)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3e01f35-91cc-4644-9882-66290ed83a02"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Create the DataFrame. This is the same one we created in the previous notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74020868-ad23-4ad5-bf43-3036c4ac8ab2"}}},{"cell_type":"code","source":["parquetDir = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d7134f2-c0c5-43b0-a9f8-c29000e133d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pagecountsEnAllDF = (spark  # Our SparkSession & Entry Point\n  .read                     # Our DataFrameReader\n  .parquet(parquetDir)      # Returns an instance of DataFrame\n)\nprint(pagecountsEnAllDF)    # Python hack to see the data type"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cb4fe6a-d412-4400-9603-f69a7ad089b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">DataFrame[project: string, article: string, requests: int, bytes_served: bigint]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">DataFrame[project: string, article: string, requests: int, bytes_served: bigint]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Execute a count on the DataFrame as we did at the end of the previous notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1859d34f-2ba6-462e-ab0a-e684ca4e98fb"}}},{"cell_type":"code","source":["total = pagecountsEnAllDF.count()\n\nprint(\"Record Count: {0:,}\".format( total ))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de0a0822-ce3d-4bfe-a01d-2f8646a5a5a8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Record Count: 2,345,943\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Record Count: 2,345,943\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["That tells us that there are around 2 million rows in the `DataFrame`. \n\nBefore we take a closer look at the contents of the `DataFrame`, let us introduce a technique that speeds up processing."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f53f346-b98b-4c1a-a949-1da639770d9a"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) cache() & persist()\n\nThe ability to cache data is one technique for achieving better performance with Apache Spark. \n\nThis is because every action requires Spark to read the data from its source (Azure Blob, Amazon S3, HDFS, etc.) but caching moves that data into the memory of the local executor for \"instant\" access.\n\n`cache()` is just an alias for `persist()`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"228f11de-d5d0-4a08-aeb4-f0e4d54bff82"}}},{"cell_type":"code","source":["(pagecountsEnAllDF\n  .cache()         # Mark the DataFrame as cached\n  .count()         # Materialize the cache\n) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f656498-04aa-4614-8a90-db9b42745f09"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: 2345943</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: 2345943</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["If you re-run that command, it should take significantly less time."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df94821c-69c9-45bd-b1d6-d71e777e4144"}}},{"cell_type":"code","source":["pagecountsEnAllDF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24bc3170-8666-4ecd-83df-624261883db4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: 2345943</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: 2345943</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Performance considerations of Caching Data\n\nWhen Caching Data you are placing it on the workers of the cluster. \n\nCaching takes resources, before moving a notebook into production please check and verify that you are appropriately using cache."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a91bccf-b063-4cb4-945f-f9269287b84d"}}},{"cell_type":"markdown","source":["And as a quick side note, you can remove a cache by calling the `DataFrame`'s `unpersist()` method but, it is not necessary."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beb7c66f-8a54-4cd7-8f53-4a4845b1e065"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Our Data\n\nLet's continue by taking a look at the type of data we have. \n\nWe can do this with the `printSchema()` command:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0748fb3-645a-4f9b-8c68-8ada4f11883c"}}},{"cell_type":"code","source":["pagecountsEnAllDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cfda131-cf28-4180-82a4-474508052304"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- project: string (nullable = true)\n |-- article: string (nullable = true)\n |-- requests: integer (nullable = true)\n |-- bytes_served: long (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- project: string (nullable = true)\n-- article: string (nullable = true)\n-- requests: integer (nullable = true)\n-- bytes_served: long (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We should now be able to see that we have four columns of data:\n* **project** (*string*): The name of the Wikipedia project. This will include values such as:\n  * **en**: The English version of Wikipedia.\n  * **fr**: The French version of Wikipedia.\n  * **en.d**: The English version of Wiktionary.\n  * **fr.b**: The French version of Wikibooks.\n  * **de.n**: The German version of Wikinews.\n* **article** (*string*): The name of the article in the corresponding project. This will include values such as:\n  * <a href=\"https://en.wikipedia.org/wiki/Apache_Spark\" target=\"_blank\">Apache_Spark</a>\n  * <a href=\"https://en.wikipedia.org/wiki/Matei_Zaharia\" target=\"_blank\">Matei_Zaharia</a>\n  * <a href=\"https://en.wikipedia.org/wiki/Kevin_Bacon\" target=\"_blank\">Kevin_Bacon</a>\n* **requests** (*integer*): The number of requests (clicks) the article has received in the hour this data represents.\n* **bytes_served** (*long*): The total number of bytes delivered for the requested article.\n  * **Note:** In our copy of the data, this value is zero for all records and consequently is of no value to us."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66a58d01-c361-4a60-974d-16655f6f50b0"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Spark API\n\nYou have already seen one command available to the `DataFrame` class, namely `DataFrame.printSchema()`\n  \nLet's take a look at the API to see what other operations we have available."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b5a957e-bed6-493c-89c4-1dccd5792942"}}},{"cell_type":"markdown","source":["### **Spark API Home Page**\n0. Open a new browser tab\n0. Google for **Spark API Latest** or **Spark API _x.x.x_** for a specific version.\n0. Select **Spark API Documentation - Spark _x.x.x_ Documentation - Apache Spark** \n\nOther Documentation:\n* Programming Guides for DataFrames, SQL, Graphs, Machine Learning, Streaming...\n* Deployment Guides for Spark Standalone, Mesos, Yarn...\n* Configuration, Monitoring, Tuning, Security...\n\nHere are some shortcuts\n  * <a href=\"https://spark.apache.org/docs/latest/\" target=\"_blank\">Spark API Documentation - Latest</a>\n  * <a href=\"https://spark.apache.org/docs/2.1.1/api.html\" target=\"_blank\">Spark API Documentation - 2.1.1</a>\n  * <a href=\"https://spark.apache.org/docs/2.1.0/api.html\" target=\"_blank\">Spark API Documentation - 2.1.0</a>\n  * <a href=\"https://spark.apache.org/docs/2.0.2/api.html\" target=\"_blank\">Spark API Documentation - 2.0.2</a>\n  * <a href=\"https://spark.apache.org/docs/1.6.3/api.html\" target=\"_blank\">Spark API Documentation - 1.6.3</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f03dd17-ee8a-495b-b1f5-442c22c8fd08"}}},{"cell_type":"markdown","source":["Naturally, which set of documentation you will use depends on which language you will use."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fe76860-877c-4435-9a29-4c50ee28c8bc"}}},{"cell_type":"markdown","source":["### Spark API (Python)\n\n0. Select **Spark Python API (Sphinx)**.\n0. Look up the documentation for `pyspark.sql.DataFrame`.\n  0. In the lower-left-hand-corner type **DataFrame** into the search field.\n  0. Hit **[Enter]**.\n  0. The search results should appear in the right-hand pane.\n  0. Click on **pyspark.sql.DataFrame (Python class, in pyspark.sql module)**\n  0. The documentation should open in the right-hand pane."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23b02c3c-3065-4e83-8f41-3f30006fd875"}}},{"cell_type":"markdown","source":["### Spark API (Scala)\n\n0. Select **Spark Scala API (Scaladoc)**.\n0. Look up the documentation for `org.apache.spark.sql.DataFrame`.\n  0. In the upper-left-hand-corner type **DataFrame** into the search field.\n  0. The search will execute automatically.\n  0. In the class/package list, click on **DataFrame**.\n  0. The documentation should open in the right-hand pane.\n  \nThis isn't going to work, but why?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a1901d3-660c-47c8-8147-bb3a42d99b27"}}},{"cell_type":"markdown","source":["### Spark API (Scala), Try #2\n\nLook up the documentation for `org.apache.spark.sql.Dataset`.\n  0. In the upper-left-hand-corner type **Dataset** into the search field.\n  0. The search will execute automatically.\n  0. In the class/package list, click on **Dataset**.\n  0. The documentation should open in the right-hand pane."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3c2a5da-e68c-47af-a953-ade302c94acf"}}},{"cell_type":"markdown","source":["Now that we have found the proper documentation, we can take a quick peek at the function `printSchema()`.\n\nNothing special here.\n\nIf you look at the API docs, `printSchema(..)` is described like this:\n> Prints the schema to the console in a nice tree format."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"922edbde-186a-4791-b511-502aa9b5cf10"}}},{"cell_type":"markdown","source":["## Next steps\n\nStart the next lesson, [Use the Display function]($./3.Display-function)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efee9892-e77e-4319-a3b9-8e6b3ebc79b6"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2.Use-common-dataframe-methods","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3013059022293262}},"nbformat":4,"nbformat_minor":0}
